# FinetuningBERT_TextClassification
 
<!-- TABLE OF CONTENTS -->
<details open="open">
  <summary><h2 style="display: inline-block">Table of Contents</h2></summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#built-with">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#contributing">Contributing</a></li>
  </ol>
</details>


<!-- ABOUT THE PROJECT -->
## About The Project

BERT (Bidirectional Encoder Representations from Transformers) was developed by Google AI as a "swiss-army knife" to answer many of natural language processing (NLP) problems, including sentiment analysis, question answering, text generation, summarization, and text prediction. Training a natural language learning model such as BERT is very expensive and time-consuming because of the large number of parameters (110M+) and the massive amount of traning data (3.3 billion words). Therefore, we utilize transfer learning with Tensorflow and Tensorflow Hub in order to finetune a pre-trained BERT model onto our dataset, which is a selection of sincere and insincere questions from Quora.com, in order to classify whether or not a question is authentic.

### Built With

* []()Python


<!-- GETTING STARTED -->
## Getting Started

To get a local copy up and running follow these steps.

### Prerequisites

This is a list of packages that need to be installed before the notebook can be run.
* python
* tensorflow


### Installation

Clone the repo: https://github.com/calvinma888/FinetuningBERT_TextClassification.git

### Datasets
The dataset can be found in the cloned repository.

<!-- USAGE EXAMPLES -->
## Usage

Run with Jupyter Notebook or Google Colab


<!-- CONTRIBUTING -->
## Contributing

Calvin (Yu chien) Ma

